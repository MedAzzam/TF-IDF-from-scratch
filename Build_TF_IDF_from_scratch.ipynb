{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MedAzzam/TF-IDF-from-scratch/blob/main/Build_TF_IDF_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b95b417",
      "metadata": {
        "id": "5b95b417"
      },
      "source": [
        "# TF-IDF From Scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![TF-IDF](https://miro.medium.com/v2/1*swXqNsBUqcysa72mcb1_kw.png)"
      ],
      "metadata": {
        "id": "EXIE__hBEH7S"
      },
      "id": "EXIE__hBEH7S"
    },
    {
      "cell_type": "markdown",
      "id": "55dc955d",
      "metadata": {
        "id": "55dc955d"
      },
      "source": [
        "# Libraries & data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7ef3381",
      "metadata": {
        "id": "d7ef3381"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import nltk\n",
        "\n",
        "from nltk import word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b8a115f",
      "metadata": {
        "id": "6b8a115f"
      },
      "outputs": [],
      "source": [
        "dir_path = \"C:/Users/pc/Documents/Python files/NLP/bbc\"\n",
        "\n",
        "data = []\n",
        "\n",
        "for foldername in os.listdir(dir_path):\n",
        "    if not os.path.isdir(os.path.join(dir_path, foldername)):\n",
        "        continue\n",
        "    for filename in os.listdir(os.path.join(dir_path, foldername)):\n",
        "        if filename.endswith(\".txt\"):\n",
        "            with open(os.path.join(dir_path, foldername, filename), \"r\") as f:\n",
        "                content = f.read()\n",
        "                data.append({\"foldername\": foldername, \"filename\": filename, \"content\": content})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e449cc87",
      "metadata": {
        "id": "e449cc87"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(data)\n",
        "\n",
        "df.to_csv(\"output.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19b84351",
      "metadata": {
        "id": "19b84351",
        "outputId": "6f928cdf-b0c9-42db-949e-75ae1ce92604"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>foldername</th>\n",
              "      <th>filename</th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>business</td>\n",
              "      <td>001.txt</td>\n",
              "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>business</td>\n",
              "      <td>002.txt</td>\n",
              "      <td>Dollar gains on Greenspan speech\\n\\nThe dollar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>business</td>\n",
              "      <td>003.txt</td>\n",
              "      <td>Yukos unit buyer faces loan claim\\n\\nThe owner...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>business</td>\n",
              "      <td>004.txt</td>\n",
              "      <td>High fuel prices hit BA's profits\\n\\nBritish A...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>business</td>\n",
              "      <td>005.txt</td>\n",
              "      <td>Pernod takeover talk lifts Domecq\\n\\nShares in...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  foldername filename                                            content\n",
              "0   business  001.txt  Ad sales boost Time Warner profit\\n\\nQuarterly...\n",
              "1   business  002.txt  Dollar gains on Greenspan speech\\n\\nThe dollar...\n",
              "2   business  003.txt  Yukos unit buyer faces loan claim\\n\\nThe owner...\n",
              "3   business  004.txt  High fuel prices hit BA's profits\\n\\nBritish A...\n",
              "4   business  005.txt  Pernod takeover talk lifts Domecq\\n\\nShares in..."
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1de496f",
      "metadata": {
        "id": "a1de496f",
        "outputId": "e3fb413a-2e96-45a4-fb0d-65b5628c6e75"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Error loading puntk: Package 'puntk' not found in index\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('puntk')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b46cb1d",
      "metadata": {
        "id": "4b46cb1d",
        "outputId": "7a62f732-a09e-4b03-8a30-e2733ca1ce0b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>foldername</th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>business</td>\n",
              "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>business</td>\n",
              "      <td>Dollar gains on Greenspan speech\\n\\nThe dollar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>business</td>\n",
              "      <td>Yukos unit buyer faces loan claim\\n\\nThe owner...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>business</td>\n",
              "      <td>High fuel prices hit BA's profits\\n\\nBritish A...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>business</td>\n",
              "      <td>Pernod takeover talk lifts Domecq\\n\\nShares in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2220</th>\n",
              "      <td>tech</td>\n",
              "      <td>BT program to beat dialler scams\\n\\nBT is intr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2221</th>\n",
              "      <td>tech</td>\n",
              "      <td>Spam e-mails tempt net shoppers\\n\\nComputer us...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2222</th>\n",
              "      <td>tech</td>\n",
              "      <td>Be careful how you code\\n\\nA new European dire...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2223</th>\n",
              "      <td>tech</td>\n",
              "      <td>US cyber security chief resigns\\n\\nThe man mak...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2224</th>\n",
              "      <td>tech</td>\n",
              "      <td>Losing yourself in online gaming\\n\\nOnline rol...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2225 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     foldername                                            content\n",
              "0      business  Ad sales boost Time Warner profit\\n\\nQuarterly...\n",
              "1      business  Dollar gains on Greenspan speech\\n\\nThe dollar...\n",
              "2      business  Yukos unit buyer faces loan claim\\n\\nThe owner...\n",
              "3      business  High fuel prices hit BA's profits\\n\\nBritish A...\n",
              "4      business  Pernod takeover talk lifts Domecq\\n\\nShares in...\n",
              "...         ...                                                ...\n",
              "2220       tech  BT program to beat dialler scams\\n\\nBT is intr...\n",
              "2221       tech  Spam e-mails tempt net shoppers\\n\\nComputer us...\n",
              "2222       tech  Be careful how you code\\n\\nA new European dire...\n",
              "2223       tech  US cyber security chief resigns\\n\\nThe man mak...\n",
              "2224       tech  Losing yourself in online gaming\\n\\nOnline rol...\n",
              "\n",
              "[2225 rows x 2 columns]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.drop(\"filename\", axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53354e7b",
      "metadata": {
        "id": "53354e7b"
      },
      "source": [
        "### Populate word2idx\n",
        "   - **convert documents into sequences of ints / ids / indices**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d95f09c",
      "metadata": {
        "id": "9d95f09c"
      },
      "outputs": [],
      "source": [
        "idx = 0\n",
        "word2idx = {}\n",
        "tokenized_docs = []\n",
        "for doc in df['content']:\n",
        "    words = word_tokenize(doc.lower())\n",
        "    doc_as_int = []\n",
        "    for word in words:\n",
        "        if word not in word2idx:\n",
        "            word2idx[word] = idx\n",
        "            idx += 1\n",
        "\n",
        "        # Save for later\n",
        "        doc_as_int.append(word2idx[word])\n",
        "    tokenized_docs.append(doc_as_int)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ebbbb891",
      "metadata": {
        "id": "ebbbb891"
      },
      "source": [
        " - **reverse mapping**\n",
        " - **if you do it smarter you can store it as a list**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2775dc3e",
      "metadata": {
        "id": "2775dc3e"
      },
      "outputs": [],
      "source": [
        "idx2word = {v:k for k, v in word2idx.items()}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9709cdad",
      "metadata": {
        "id": "9709cdad"
      },
      "source": [
        " - **number of documents**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df2ac762",
      "metadata": {
        "id": "df2ac762"
      },
      "outputs": [],
      "source": [
        "N = len(df['content'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a62dd0f0",
      "metadata": {
        "id": "a62dd0f0"
      },
      "source": [
        " - **number of words**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4693c8b",
      "metadata": {
        "id": "a4693c8b"
      },
      "outputs": [],
      "source": [
        "V = len(word2idx)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a42faf2",
      "metadata": {
        "id": "7a42faf2"
      },
      "source": [
        " - **instantiate term-frequency matrix**\n",
        " - **note: could have also used count vectoriser**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b29f549",
      "metadata": {
        "id": "5b29f549"
      },
      "outputs": [],
      "source": [
        "tf = np.zeros((N,V))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "778fd8fb",
      "metadata": {
        "id": "778fd8fb"
      },
      "source": [
        " - **populate term-fequency matrix**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "678703a6",
      "metadata": {
        "id": "678703a6"
      },
      "outputs": [],
      "source": [
        "for i, doc_as_int in enumerate(tokenized_docs):\n",
        "    for j in doc_as_int:\n",
        "        tf[i, j] = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bdedc9b8",
      "metadata": {
        "id": "bdedc9b8"
      },
      "source": [
        " - **compute term-frequency counts**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c26e7eb",
      "metadata": {
        "id": "0c26e7eb"
      },
      "outputs": [],
      "source": [
        "document_freq = np.sum(tf>0, axis=0)  # document feaquency (shape = (V,))\n",
        "idf = np.log(N / document_freq)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34bb998a",
      "metadata": {
        "id": "34bb998a"
      },
      "source": [
        " - **compute TF-IDF**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f903723d",
      "metadata": {
        "id": "f903723d"
      },
      "outputs": [],
      "source": [
        "tf_idf = tf * idf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47bfdc4c",
      "metadata": {
        "id": "47bfdc4c"
      },
      "outputs": [],
      "source": [
        "np.random.seed(123)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6d88624",
      "metadata": {
        "id": "e6d88624"
      },
      "source": [
        " - **pick a random document, show the top 5 terms (in terms of tf_idf score)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "513447f2",
      "metadata": {
        "id": "513447f2",
        "outputId": "aefbe8d5-95bc-4add-f1bd-582ed15b8374"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label: tech\n",
            "content: IBM puts cash behind Linux push\n",
            "Top 5 terms:\n",
            "beefing\n",
            "premise\n",
            "tinker\n",
            "digit\n",
            "suite\n"
          ]
        }
      ],
      "source": [
        "i = np.random.choice(N)\n",
        "row = df.iloc[i]\n",
        "print(\"Label:\", row['foldername'])\n",
        "print(\"content:\", row['content'].split(\"\\n\",1)[0])\n",
        "print(\"Top 5 terms:\")\n",
        "\n",
        "scores = tf_idf[i]\n",
        "indices = (-scores).argsort()\n",
        "\n",
        "for j in indices[:5]:\n",
        "    print(idx2word[j])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}